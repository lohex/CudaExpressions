{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import cuda\n",
    "import numpy as np\n",
    "import sympy as sp\n",
    "\n",
    "import CudaExpression as ce"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating a symbolic expression on a GPU\n",
    "\n",
    "First the expression is defined as a string and parameter values are created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = 'H0*k1/(k2 + k3) - H1*k3/(k1 - k2) - k0'\n",
    "n = 1000000\n",
    "R = np.random.uniform(0,1,(n,6))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the expression on a set of parameters, the eval method can be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 547 ms\n",
      "Wall time: 585 ms\n"
     ]
    }
   ],
   "source": [
    "gpu_expr = ce.GPUExpression(expression)\n",
    "%time gpu_results = gpu_expr.eval(R)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the expression from within a kernel, the structure of the expression can be passed to the CudaExpression.eval_inline function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using the tensor representation to evaluate the expression from within a kernel\n",
    "@cuda.jit\n",
    "def kernel(params,expression_tensor,eval_buffer,results):\n",
    "    i = cuda.grid(1)\n",
    "    if i < params.shape[0]:\n",
    "         results[i] = ce.eval_inline(expression_tensor,params[i],eval_buffer[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 156 ms\n",
      "Wall time: 164 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cuTensor = gpu_expr.toTensor(on_device=True)\n",
    "\n",
    "cuR = cuda.to_device(R)\n",
    "buffer = np.zeros((n,cuTensor.shape[0]))\n",
    "cuBuffer = cuda.to_device(buffer)\n",
    "results = np.zeros(n)\n",
    "cuResults = cuda.to_device(results)\n",
    "\n",
    "kernel[1000,1000](cuR,cuTensor,cuBuffer,cuResults)\n",
    "cuda.synchronize()\n",
    "results = cuResults.copy_to_host()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cuda version runs much faster than the numpy version on CPU but deliveres the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.53 s\n",
      "Wall time: 1.53 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate the expression on the example parametrs using numpy to verify the results\n",
    "function_numpy = gpu_expr.toNumpy(on_array=True)\n",
    "%time results_numpy = function_numpy(R)\n",
    "np.allclose( results, results_numpy )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorial expressions\n",
    "\n",
    "A set of expressions (a vector function) can be created. The class\n",
    "* returns an vector\n",
    "* exploits sparsity of the vector\n",
    "* exploits repetitive expressions between the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a vectorial expression\n",
    "vector_expression = ['k4/(k1*k2)','k1/k4+k3/k2','k1+k2/(k1-k3)','k4 + k2']\n",
    "# generating example parameters\n",
    "n = 1000000\n",
    "R2 = np.random.uniform(0,1,(n,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 312 ms\n",
      "Wall time: 314 ms\n"
     ]
    }
   ],
   "source": [
    "gpu_vec = ce.GPUExpressionVector(vector_expression)\n",
    "%time results = gpu_vec.eval(R2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2.78 s\n",
      "Wall time: 2.78 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_expr_numpy = gpu_vec.toNumpy()\n",
    "%time results_numpy = vector_expr_numpy(R2)\n",
    "np.allclose(results_numpy.reshape([R2.shape[0],-1]),results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
